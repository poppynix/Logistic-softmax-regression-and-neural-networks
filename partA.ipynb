{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2191d47b",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "\n",
    "torch – the main PyTorch library for building and training neural networks.\n",
    "\n",
    "numpy – used for numerical operations and array manipulations.\n",
    "\n",
    "torchvision.datasets and torchvision.transforms – for loading and preprocessing image datasets.\n",
    "\n",
    "TensorDataset and DataLoader from torch.utils.data – to wrap data into tensors (multi-dimensional arrays) and efficiently load it in batches during training.\n",
    "\n",
    "train_test_split from sklearn.model_selection – to split our dataset into training and testing subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac1988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa7388",
   "metadata": {},
   "source": [
    "## Setting Hyperparameters and Configuration Values\n",
    "\n",
    "#### RANDOM_SEED = 42\n",
    "Ensures reproducibility — setting a fixed random seed makes sure that data splits, weight initialization, and other random operations give the same results each run.\n",
    "\n",
    "#### BATCH_SIZE = 64\n",
    "The number of samples processed before the model updates its parameters.\n",
    "A typical starting point that balances speed and stability.\n",
    "\n",
    "#### LR = 0.01\n",
    "Controls how fast or slow the model learns during optimization.\n",
    "\n",
    "#### INPUT_SIZE = 784  # 28 × 28\n",
    "Each MNIST image (28×28 pixels) is flattened into a 784-dimensional vector, which serves as the input size for our model.\n",
    "\n",
    "#### TEST_VALID_SIZE = 0.4\n",
    "Specifies that 40% of the total data will be temporarily held out, to later be split evenly into validation (20%) and test (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0f9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42 \n",
    "BATCH_SIZE = 64\n",
    "LR = 0.01 \n",
    "INPUT_SIZE = 784 \n",
    "TEST_VALID_SIZE = 0.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a33102",
   "metadata": {},
   "source": [
    "## Data Preparation (A1)\n",
    "\n",
    "#### 1. Define Transformations and Load Full Data\n",
    "    ToTensor() – converts each image to a PyTorch tensor and normalizes pixel values to the range [0, 1].\n",
    "\n",
    "    Lambda(lambda x: x.flatten()) – reshapes each 28×28 grayscale image into a single vector of 784 values.\n",
    "\n",
    "The MNIST training (60k) and test (10k) sets are both loaded, giving a total of 70,000 images.\n",
    "\n",
    "#### 2. Combine and Split the Dataset\n",
    "\n",
    "The full dataset is merged, normalized, and flattened, then, a two-step stratified split is performed using train_test_split:\n",
    "\n",
    "    Step 1: 60% Training, 40% Temporary\n",
    "\n",
    "    Step 2: Temporary (40%) → 20% Validation + 20% Test\n",
    "\n",
    "stratify=y_combined ensures all subsets preserve the same class distribution across digits 0–9.\n",
    "\n",
    "After splitting, all NumPy arrays are converted back to PyTorch tensors:\n",
    "\n",
    "    X_train = torch.tensor(X_train_np).float()\n",
    "    y_train = torch.tensor(y_train_np)\n",
    "\n",
    "#### 3. Create DataLoaders (10-Class)\n",
    "\n",
    "The train, validation, and test tensors are wrapped into TensorDatasets and passed into DataLoaders for efficient batching and shuffling:\n",
    "\n",
    "    DATA_LOADERS_FULL = {\n",
    "        'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True),\n",
    "        'val': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False),\n",
    "        'test': DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    }\n",
    "\n",
    "shuffle=True → randomizes training order for better generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part A1 Complete. Train Size: 42000, Validation Size: 14000, Test Size: 14000\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Transformation & Load Full Data\n",
    "linear_model_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "train_set_full = datasets.MNIST('./data', train=True, download=True, transform=linear_model_transforms)\n",
    "test_set_full = datasets.MNIST('./data', train=False, download=True, transform=linear_model_transforms)\n",
    "\n",
    "# Combine datasets into single tensors for stratified split\n",
    "# NOTE: We combine the normalized, flattened Tensors here\n",
    "X_combined = torch.cat([train_set_full.data.float().div(255).flatten(start_dim=1),\n",
    "                        test_set_full.data.float().div(255).flatten(start_dim=1)], dim=0).numpy()\n",
    "y_combined = torch.cat([train_set_full.targets, test_set_full.targets], dim=0).numpy()\n",
    "\n",
    "# Step 1: Split into Training (60%) and Temporary (40%)\n",
    "X_train_np, X_temp_np, y_train_np, y_temp_np = train_test_split(\n",
    "    X_combined, y_combined, \n",
    "    test_size=TEST_VALID_SIZE, \n",
    "    random_state=RANDOM_SEED, \n",
    "    stratify=y_combined \n",
    ")\n",
    "\n",
    "# Step 2: Split Temporary (40%) into Validation (20%) and Test (20%)\n",
    "X_val_np, X_test_np, y_val_np, y_test_np = train_test_split(\n",
    "    X_temp_np, y_temp_np, \n",
    "    test_size=0.5, \n",
    "    random_state=RANDOM_SEED, \n",
    "    stratify=y_temp_np \n",
    ")\n",
    "\n",
    "# Convert arrays back to PyTorch Tensors (for A2 filtering)\n",
    "X_train = torch.tensor(X_train_np).float()\n",
    "X_val = torch.tensor(X_val_np).float()\n",
    "X_test = torch.tensor(X_test_np).float()\n",
    "\n",
    "y_train = torch.tensor(y_train_np)\n",
    "y_val = torch.tensor(y_val_np)\n",
    "y_test = torch.tensor(y_test_np)\n",
    "\n",
    "# 3. Create Full DataLoaders (10-Class)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "DATA_LOADERS_FULL = {\n",
    "    'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True),\n",
    "    'val': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False),\n",
    "    'test': DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "}\n",
    "\n",
    "print(f\"Part A1 Complete. Train Size: {len(X_train)}, Validation Size: {len(X_val)}, Test Size: {len(X_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
